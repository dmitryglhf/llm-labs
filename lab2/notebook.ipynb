{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "Hbol",
   "metadata": {},
   "outputs": [],
   "source": [
    "import marimo as mo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "MJUe",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "# Лабораторная работа 2: Мультиагентный помощник по учёбе и продуктивности\n",
    "\n",
    "Данный ноутбук реализует мультиагентную систему с использованием LangChain и LangGraph для помощи в учёбе, программировании и задачах продуктивности.\n",
    "\n",
    "## Архитектура системы\n",
    "\n",
    "Система состоит из 4 специализированных агентов.\n",
    "\n",
    "**Агент-роутер** классифицирует запросы пользователя и определяет, какой агент должен быть активирован. Использует условную маршрутизацию (conditional routing) для передачи управления.\n",
    "\n",
    "**Агент теории** обрабатывает концептуальные и теоретические вопросы о мультиагентных системах и больших языковых моделях.\n",
    "\n",
    "**Агент планирования** помогает с планированием задач, продуктивностью и программированием. Использует инструменты работы со временем, создания планов, веб-поиска документации и навигации по файловой системе проекта.\n",
    "\n",
    "**Агент памяти** управляет историей сессии и контекстом пользователя. Сохраняет память в файл.\n",
    "\n",
    "## Паттерн МАС: Роутер + Специализированные агенты с условной маршрутизацией\n",
    "\n",
    "Система использует паттерн роутера, где агент-роутер анализирует входящие запросы и направляет их к соответствующему специализированному агенту через условные рёбра графа. На основе классификации активируется только ОДИН агент на каждый запрос.\n",
    "\n",
    "## ASCII-схема потока управления и данных\n",
    "\n",
    "```\n",
    "                       ┌──────────────────┐\n",
    "                       │ Запрос           │\n",
    "                       │ пользователя     │\n",
    "                       └────────┬─────────┘\n",
    "                                │\n",
    "                                ▼\n",
    "                       ┌────────────────────┐\n",
    "                       │  Агент-роутер      │\n",
    "                       │  (классификация)   │\n",
    "                       └─────┬──────────────┘\n",
    "                             │\n",
    "                ┌────────────┼────────────┐\n",
    "                │            │            │\n",
    "           [теория]    [планирование]  [общее]\n",
    "                │            │            │\n",
    "                ▼            ▼            ▼\n",
    "        ┌──────────┐  ┌──────────┐  ┌──────────┐\n",
    "        │  Агент   │  │  Агент   │  │  Агент   │\n",
    "        │  теории  │  │планиро-  │  │  памяти  │\n",
    "        │          │  │  вания   │  │          │\n",
    "        └────┬─────┘  └────┬─────┘  └────┬─────┘\n",
    "             │             │             │\n",
    "             └─────────────┼─────────────┘\n",
    "                           ▼\n",
    "                  ┌────────────────┐\n",
    "                  │  Агент памяти  │\n",
    "                  │ (финализация)  │\n",
    "                  └────────┬───────┘\n",
    "                           │\n",
    "                           ▼\n",
    "                  ┌────────────────┐\n",
    "                  │   Финальный    │\n",
    "                  │     ответ      │\n",
    "                  └────────────────┘\n",
    "```\n",
    "\n",
    "## Использование инструментов (Tool Calling)\n",
    "\n",
    "**Агент теории** использует инструменты `search_wikipedia` и `get_wikipedia_article` для поиска и получения теоретических концепций.\n",
    "\n",
    "**Агент планирования** использует расширенный набор инструментов: `get_current_time`, `create_study_plan`, `list_study_materials`, `read_study_material` для управления временем и планами обучения, а также `web_search` для поиска документации и примеров кода, `list_files` для навигации по файловой системе проекта и `read_code_file` для чтения исходного кода.\n",
    "\n",
    "**Агент памяти** использует инструменты `save_memory` и `load_memory` для сохранения и загрузки данных сессии.\n",
    "\n",
    "## Управление памятью (Memory Management)\n",
    "\n",
    "История сессии хранится в состоянии (state) и персистентно сохраняется в JSON-файл. Предыдущие взаимодействия загружаются и используются для улучшения маршрутизации и ответов. Память влияет на ответы агентов через инъекцию контекста в промпты.\n",
    "\n",
    "## Эксперименты и оценка\n",
    "\n",
    "Система протестирована на пяти запросах различного типа. Все запросы корректно классифицированы с высокой уверенностью (0.95).\n",
    "\n",
    "Запрос 1 (теория о вызовах МАС с LLM): активирован агент теории, использованы инструменты Wikipedia для получения информации о координации агентов, масштабируемости и управлении знаниями. Ответ содержит детальный анализ пяти ключевых проблем с примерами и ссылками. Память обновлена с указанием интереса пользователя к теоретическим аспектам МАС.\n",
    "\n",
    "Запрос 2 (план изучения МАС на 10 часов): активирован агент планирования, создан структурированный план с разбиением на 5 сессий по 2 часа, включающий темы от основ до продвинутых концепций и практики. Инструмент create_study_plan сгенерировал JSON со списком задач для каждой сессии. Рекомендации включают перерывы, онлайн-курсы и практические упражнения на платформах JADE и NetLogo.\n",
    "\n",
    "Запрос 3 (различия между supervisor и sequential workflow): активирован агент теории, выполнен поиск по обоим паттернам. Ответ содержит детальное сравнение централизованного управления supervisor против линейной последовательности workflow, таблицу различий по шести критериям и примеры применения. Память зафиксировала углубление в архитектурные паттерны МАС.\n",
    "\n",
    "Запрос 4 (расписание на 5 дней для LangGraph): активирован агент планирования, создан план с распределением 2 часов в день на изучение концепций графов, манипуляции структурами, оптимизации запросов и реальных применений. Инструмент create_study_plan адаптировал длительность под формат \"дни\". Рекомендации включают ссылки на учебные материалы (PDF, notebooks, papers из study_materials).\n",
    "\n",
    "Запрос 5 (координация и коммуникация в МАС): активирован агент теории, поиск информации о протоколах коммуникации и децентрализованных алгоритмах. Ответ объясняет методы координации (переговоры, децентрализованные алгоритмы, MARL), элементы коммуникации (протоколы FIPA-ACL, семантическая совместимость) и связь с Distributed AI. Приведены примеры применения в робототехнике и логистике.\n",
    "\n",
    "Неформальная оценка по критериям:\n",
    "\n",
    "Корректность маршрутизации: 100% (5 из 5 запросов направлены к нужному агенту). Роутер использует контекст предыдущих запросов для повышения точности классификации.\n",
    "\n",
    "Использование инструментов: осмысленное и целевое. Агент теории обращается к Wikipedia для фактов, агент планирования создает структурированные планы через create_study_plan и использует web_search для документации. Ложных вызовов не обнаружено.\n",
    "\n",
    "Работа с памятью: память активно используется. После каждого запроса агент памяти обновляет session_history, извлекает паттерны поведения (темы интереса, стиль ответов) и сохраняет в JSON. Последующие запросы учитывают накопленный контекст для построения связных объяснений.\n",
    "\n",
    "Субъективная полезность: ответы содержат детальные объяснения с терминологией, ссылками, примерами. Планы структурированы с разбивкой на этапы и ресурсы. Система пригодна для реального использования при изучении МАС и планировании учебных задач.\n",
    "\n",
    "Ограничения: иногда ответы избыточны по объему. Агент планирования генерирует общие рекомендации, не всегда учитывая специфику темы. Инструменты Wikipedia иногда не находят точных совпадений для специфичных терминов из МАС.\n",
    "\n",
    "## Рефлексия\n",
    "\n",
    "Хорошо сработали: паттерн роутера с условной маршрутизацией обеспечил четкое разделение ответственности между агентами без конфликтов. Использование memory agent для финализации ответов позволило централизовать управление историей и избежать дублирования логики сохранения. Tool calling через LangChain agents упростил интеграцию инструментов без необходимости ручного парсинга и маршрутизации вызовов.\n",
    "\n",
    "Неожиданное поведение: роутер иногда классифицирует запросы о применении теории как \"planning\" вместо \"theory\", что связано с неоднозначностью формулировок. Агент планирования при создании планов иногда генерирует избыточное количество ресурсов, не все из которых релевантны. Wikipedia search иногда возвращает статьи на неправильном языке, несмотря на русскоязычный запрос.\n",
    "\n",
    "Направления развития: добавить агента-ревьюера для проверки качества ответов перед финализацией (supervisor pattern поверх существующей архитектуры). Реализовать RAG для работы с локальной базой знаний вместо зависимости от Wikipedia. Расширить набор инструментов агента планирования: интеграция с календарями, трекерами задач, Git для анализа истории проектов. Улучшить память через векторную БД для семантического поиска по истории вместо простого списка."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "vblA",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "\n",
    "import wikipedia\n",
    "from ddgs import DDGS\n",
    "from langchain.tools import tool\n",
    "from logly import logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bkHC",
   "metadata": {},
   "outputs": [],
   "source": [
    "MEMORY_FILE = Path(\"lab2_memory.json\")\n",
    "STUDY_MATERIALS_DIR = Path(\"study_materials\")\n",
    "STUDY_MATERIALS_DIR.mkdir(parents=True, exist_ok=True)\n",
    "CODE_ROOT_DIR = Path.cwd()  # Root directory for code search\n",
    "\n",
    "@tool\n",
    "def save_memory(session_history: str, user_preferences: str) -> str:\n",
    "    \"\"\"Save session history and user preferences to persistent storage\"\"\"\n",
    "    try:\n",
    "        data = {\n",
    "            \"session_history\": json.loads(session_history),\n",
    "            \"user_preferences\": json.loads(user_preferences),\n",
    "            \"last_updated\": datetime.now().isoformat(),\n",
    "        }\n",
    "        MEMORY_FILE.write_text(json.dumps(data, indent=2))\n",
    "        logger.debug(f\"Memory saved: {len(data['session_history'])} sessions\")\n",
    "        return f\"Memory saved successfully at {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to save memory: {e}\")\n",
    "        return f\"Error saving memory: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def load_memory() -> str:\n",
    "    \"\"\"Load session history and user preferences from persistent storage\"\"\"\n",
    "    try:\n",
    "        if not MEMORY_FILE.exists():\n",
    "            logger.debug(\"No existing memory file found\")\n",
    "            return json.dumps({\"session_history\": [], \"user_preferences\": {}})\n",
    "\n",
    "        data = json.loads(MEMORY_FILE.read_text())\n",
    "        logger.debug(\n",
    "            f\"Memory loaded: {len(data.get('session_history', []))} sessions\"\n",
    "        )\n",
    "        return json.dumps(data)\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Failed to load memory: {e}\")\n",
    "        return json.dumps({\"session_history\": [], \"user_preferences\": {}})\n",
    "\n",
    "@tool\n",
    "def get_current_time() -> str:\n",
    "    \"\"\"Get current date and time\"\"\"\n",
    "    return datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")\n",
    "\n",
    "@tool\n",
    "def create_study_plan(topic: str, duration_hours: int) -> str:\n",
    "    \"\"\"Create structured study plan for given topic and duration\"\"\"\n",
    "    logger.debug(f\"Creating study plan for: {topic}, {duration_hours}h\")\n",
    "    plan = {\n",
    "        \"topic\": topic,\n",
    "        \"duration_hours\": duration_hours,\n",
    "        \"schedule\": [],\n",
    "        \"resources\": [],\n",
    "    }\n",
    "\n",
    "    hours_per_session = 2\n",
    "    num_sessions = max(1, duration_hours // hours_per_session)\n",
    "\n",
    "    for i in range(num_sessions):\n",
    "        plan[\"schedule\"].append(\n",
    "            {\n",
    "                \"session\": i + 1,\n",
    "                \"focus\": f\"Part {i + 1} of {topic}\",\n",
    "                \"duration\": f\"{hours_per_session} hours\",\n",
    "                \"start_time\": f\"Day {(i // 3) + 1}, Session {(i % 3) + 1}\",\n",
    "            }\n",
    "        )\n",
    "\n",
    "    plan[\"resources\"].extend(\n",
    "        [\n",
    "            f\"Online tutorial for {topic}\",\n",
    "            f\"Academic papers on {topic}\",\n",
    "            f\"Practical exercises for {topic}\",\n",
    "            \"Interactive coding challenges\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    return json.dumps(plan, indent=2)\n",
    "\n",
    "@tool\n",
    "def search_wikipedia(query: str, max_results: int = 3) -> str:\n",
    "    \"\"\"Search Wikipedia and return summaries of top articles for theoretical concepts\"\"\"\n",
    "    logger.debug(f\"Searching Wikipedia for: {query}\")\n",
    "    try:\n",
    "        results = wikipedia.search(query, results=max_results)\n",
    "        summaries = []\n",
    "        for title in results[:max_results]:\n",
    "            try:\n",
    "                summary = wikipedia.summary(title, sentences=2)\n",
    "                summaries.append(f\"**{title}**: {summary}\")\n",
    "            except (\n",
    "                wikipedia.exceptions.DisambiguationError,\n",
    "                wikipedia.exceptions.PageError,\n",
    "            ):\n",
    "                continue\n",
    "        return (\n",
    "            \"\\n\\n\".join(summaries)\n",
    "            if summaries\n",
    "            else f\"No results found for '{query}'\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Wikipedia search error: {e}\")\n",
    "        return f\"Error searching Wikipedia: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def get_wikipedia_article(title: str) -> str:\n",
    "    \"\"\"Get detailed content from a specific Wikipedia article\"\"\"\n",
    "    logger.debug(f\"Fetching Wikipedia article: {title}\")\n",
    "    try:\n",
    "        page = wikipedia.page(title)\n",
    "        file_path = STUDY_MATERIALS_DIR / f\"{title.replace(' ', '_')}.txt\"\n",
    "        file_path.write_text(page.content, encoding=\"utf-8\")\n",
    "        summary = wikipedia.summary(title, sentences=5)\n",
    "        return f\"**{page.title}**\\n\\n{summary}\\n\\n(Full article saved to {file_path.name})\"\n",
    "    except wikipedia.exceptions.DisambiguationError as e:\n",
    "        return f\"Ambiguous title '{title}'. Options: {', '.join(e.options[:5])}\"\n",
    "    except wikipedia.exceptions.PageError:\n",
    "        return f\"Article '{title}' not found\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Wikipedia article error: {e}\")\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def list_study_materials(folder: str = \"study_materials\") -> str:\n",
    "    \"\"\"List all downloaded study materials (articles, papers)\"\"\"\n",
    "    logger.debug(\"Listing study materials\")\n",
    "    try:\n",
    "        path = Path(folder)\n",
    "        if not path.exists():\n",
    "            return \"No study materials folder found\"\n",
    "        files = [f.name for f in path.glob(\"*\")]\n",
    "        if not files:\n",
    "            return \"No study materials downloaded yet\"\n",
    "        return f\"Study materials ({len(files)} files):\\n\" + \"\\n\".join(\n",
    "            [f\"- {f}\" for f in sorted(files)]\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"List materials error: {e}\")\n",
    "        return f\"Error listing materials: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def read_study_material(filename: str) -> str:\n",
    "    \"\"\"Read content from a downloaded study material file\"\"\"\n",
    "    logger.debug(f\"Reading study material: {filename}\")\n",
    "    try:\n",
    "        file_path = STUDY_MATERIALS_DIR / filename\n",
    "        if not file_path.exists():\n",
    "            return f\"File '{filename}' not found in study materials\"\n",
    "        if file_path.suffix == \".pdf\":\n",
    "            return f\"PDF file '{filename}' downloaded. Use a PDF reader to view it.\"\n",
    "        content = file_path.read_text(encoding=\"utf-8\")\n",
    "        return content[:2000] + (\"...\" if len(content) > 2000 else \"\")\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Read material error: {e}\")\n",
    "        return f\"Error reading file: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def web_search(\n",
    "    query: str,\n",
    "    max_results: int = 5,\n",
    "    region: str = \"us-en\",\n",
    "    safesearch: str = \"moderate\",\n",
    ") -> str:\n",
    "    \"\"\"Search the web using DuckDuckGo for programming questions, documentation, tutorials, and code examples\"\"\"\n",
    "    logger.debug(f\"Web search: {query[:50]}...\")\n",
    "    try:\n",
    "        results = DDGS().text(\n",
    "            query=query,\n",
    "            region=region,\n",
    "            safesearch=safesearch,\n",
    "            max_results=max_results,\n",
    "        )\n",
    "        logger.debug(f\"Web search: {len(results)} results found\")\n",
    "\n",
    "        formatted_results = []\n",
    "        for i, result in enumerate(results, 1):\n",
    "            formatted_results.append(\n",
    "                f\"{i}. **{result.get('title', 'No title')}**\\n\"\n",
    "                f\"   URL: {result.get('href', 'N/A')}\\n\"\n",
    "                f\"   {result.get('body', 'No description')}\"\n",
    "            )\n",
    "\n",
    "        return (\n",
    "            \"\\n\\n\".join(formatted_results)\n",
    "            if formatted_results\n",
    "            else f\"No results found for '{query}'\"\n",
    "        )\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Web search error: {e}\")\n",
    "        return f\"Error during web search: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def list_files(relative_path: str = \"\") -> str:\n",
    "    \"\"\"List files and directories in the project. Pass empty string to list current directory.\"\"\"\n",
    "    logger.debug(f\"Listing files: {relative_path or 'current directory'}\")\n",
    "    try:\n",
    "        target_path = (\n",
    "            CODE_ROOT_DIR / relative_path if relative_path else CODE_ROOT_DIR\n",
    "        )\n",
    "\n",
    "        if not target_path.exists():\n",
    "            return f\"Path '{relative_path}' does not exist\"\n",
    "\n",
    "        if not target_path.is_relative_to(CODE_ROOT_DIR):\n",
    "            return \"Access denied: path outside project directory\"\n",
    "\n",
    "        if not target_path.is_dir():\n",
    "            return f\"'{relative_path}' is not a directory\"\n",
    "\n",
    "        items = []\n",
    "        for item in sorted(target_path.iterdir()):\n",
    "            if item.name.startswith(\".\"):\n",
    "                continue\n",
    "            item_type = \"DIR\" if item.is_dir() else \"FILE\"\n",
    "            items.append(f\"[{item_type}] {item.name}\")\n",
    "\n",
    "        result = (\n",
    "            f\"Contents of '{relative_path or '.'}' ({len(items)} items):\\n\"\n",
    "            + \"\\n\".join(items)\n",
    "        )\n",
    "        logger.debug(f\"Listed {len(items)} items\")\n",
    "        return result if items else f\"Directory '{relative_path or '.'}' is empty\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"List files error: {e}\")\n",
    "        return f\"Error listing files: {str(e)}\"\n",
    "\n",
    "@tool\n",
    "def read_code_file(relative_path: str) -> str:\n",
    "    \"\"\"Read contents of a code file from the project. Use this to examine source code, configuration files, etc.\"\"\"\n",
    "    logger.debug(f\"Reading code file: {relative_path}\")\n",
    "    try:\n",
    "        file_path = CODE_ROOT_DIR / relative_path\n",
    "\n",
    "        if not file_path.exists():\n",
    "            return f\"File '{relative_path}' not found\"\n",
    "\n",
    "        if not file_path.is_relative_to(CODE_ROOT_DIR):\n",
    "            return \"Access denied: path outside project directory\"\n",
    "\n",
    "        if not file_path.is_file():\n",
    "            return f\"'{relative_path}' is not a file\"\n",
    "\n",
    "        content = file_path.read_text(encoding=\"utf-8\")\n",
    "        lines = content.split(\"\\n\")\n",
    "\n",
    "        if len(lines) > 200:\n",
    "            preview = \"\\n\".join(lines[:200])\n",
    "            return f\"File: {relative_path}\\nLines: {len(lines)} (showing first 200)\\n\\n{preview}\\n\\n... (file truncated)\"\n",
    "\n",
    "        logger.debug(f\"Read file: {len(lines)} lines\")\n",
    "        return f\"File: {relative_path}\\nLines: {len(lines)}\\n\\n{content}\"\n",
    "    except UnicodeDecodeError:\n",
    "        return f\"Cannot read '{relative_path}': binary file or encoding issue\"\n",
    "    except Exception as e:\n",
    "        logger.error(f\"Read file error: {e}\")\n",
    "        return f\"Error reading file: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "lEQa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import PydanticOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from pydantic import BaseModel, Field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "PKri",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QueryClassification(BaseModel):\n",
    "    query_type: str = Field(\n",
    "        ..., description=\"Type of query: 'theory', 'planning', or 'general'\"\n",
    "    )\n",
    "    confidence: float = Field(\n",
    "        ..., description=\"Confidence in classification (0.0-1.0)\"\n",
    "    )\n",
    "    reasoning: str = Field(..., description=\"Reasoning behind the classification\")\n",
    "\n",
    "class TheoryResponse(BaseModel):\n",
    "    answer: str = Field(..., description=\"Detailed theoretical answer\")\n",
    "    references: list[str] = Field(\n",
    "        default_factory=list, description=\"Supporting references\"\n",
    "    )\n",
    "    key_concepts: list[str] = Field(\n",
    "        default_factory=list, description=\"Key concepts covered\"\n",
    "    )\n",
    "\n",
    "class PlanningResponse(BaseModel):\n",
    "    plan: dict = Field(..., description=\"Structured plan with tasks and timeline\")\n",
    "    recommendations: list[str] = Field(\n",
    "        default_factory=list, description=\"Additional recommendations\"\n",
    "    )\n",
    "    estimated_duration: str = Field(..., description=\"Estimated time required\")\n",
    "\n",
    "class MemoryUpdate(BaseModel):\n",
    "    session_summary: str = Field(..., description=\"Summary of current session\")\n",
    "    user_preferences_updated: dict = Field(\n",
    "        default_factory=dict, description=\"Updated user preferences\"\n",
    "    )\n",
    "    action_items: list[str] = Field(\n",
    "        default_factory=list, description=\"Follow-up action items\"\n",
    "    )\n",
    "\n",
    "class MultiAgentState(BaseModel):\n",
    "    query: str = Field(..., description=\"User's input query\")\n",
    "    classification: QueryClassification | None = None\n",
    "    theory_response: TheoryResponse | None = None\n",
    "    planning_response: PlanningResponse | None = None\n",
    "    memory_update: MemoryUpdate | None = None\n",
    "    session_history: list[dict] = Field(\n",
    "        default_factory=list, description=\"Session history\"\n",
    "    )\n",
    "    user_preferences: dict = Field(\n",
    "        default_factory=dict, description=\"User preferences\"\n",
    "    )\n",
    "    final_response: str | None = None\n",
    "    errors: list[str] = Field(\n",
    "        default_factory=list, description=\"Any errors encountered\"\n",
    "    )\n",
    "    active_agent: str | None = Field(None, description=\"Currently active agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "Xref",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain.agents import create_agent\n",
    "from langchain_core.messages import HumanMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langgraph.graph import END, StateGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "SFPL",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv(find_dotenv(usecwd=True))\n",
    "\n",
    "BASE_URL = os.getenv(\"OPENAI_BASE_URL\", \"http://a6k2.dgx:34000/v1\")\n",
    "API_KEY = os.getenv(\"OPENAI_API_KEY\", \"\")\n",
    "MODEL_NAME = os.getenv(\"MODEL_NAME\", \"qwen3-32b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "BYtC",
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "    base_url=BASE_URL,\n",
    "    api_key=API_KEY,\n",
    "    model=MODEL_NAME,\n",
    "    temperature=0.7,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "RGSE",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_parser = PydanticOutputParser(pydantic_object=QueryClassification)\n",
    "\n",
    "ROUTER_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        You are a query router for a multi-agent study assistant system.\n",
    "\n",
    "        Analyze the user's query and classify it into one of these categories:\n",
    "        - 'theory': Conceptual/theoretical questions about MAS, LLMs, AI, machine learning, or academic topics\n",
    "        - 'planning': Task planning, study schedules, time management, productivity questions, programming tasks, code search, or file navigation\n",
    "        - 'general': Questions that don't fit the above categories\n",
    "\n",
    "        Consider previous session context if provided to improve classification accuracy.\n",
    "\n",
    "        Provide your classification with confidence score (0.0-1.0) and clear reasoning.\n",
    "\n",
    "        {format_instructions}\n",
    "        /no_think\n",
    "        \"\"\".strip(),\n",
    "        ),\n",
    "        (\"human\", \"Previous context: {context}\\n\\nQuery: {query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "Kclp",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_parser = PydanticOutputParser(pydantic_object=TheoryResponse)\n",
    "\n",
    "THEORY_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        You are a theory expert specializing in Multi-Agent Systems, LLMs, and AI/ML concepts.\n",
    "\n",
    "        Provide detailed, academic answers to theoretical questions. Include:\n",
    "        - Clear explanations of concepts with proper terminology\n",
    "        - Relevant references or sources (papers, books, researchers)\n",
    "        - Key concepts and their relationships\n",
    "        - Practical implications where relevant\n",
    "        - Concrete examples to illustrate abstract concepts\n",
    "\n",
    "        Consider the user's previous questions to provide continuity in explanations.\n",
    "\n",
    "        {format_instructions}\n",
    "        /no_think\n",
    "        \"\"\".strip(),\n",
    "        ),\n",
    "        (\"human\", \"Previous context: {context}\\n\\nQuestion: {query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "emfo",
   "metadata": {},
   "outputs": [],
   "source": [
    "planning_parser = PydanticOutputParser(pydantic_object=PlanningResponse)\n",
    "\n",
    "PLANNING_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        You are a planning and programming expert specializing in study schedules, productivity, and code assistance.\n",
    "\n",
    "        Create structured plans with:\n",
    "        - Clear tasks broken into manageable steps\n",
    "        - Realistic time estimates based on task complexity\n",
    "        - Resource recommendations (books, courses, tools, documentation)\n",
    "        - Actionable steps with priorities\n",
    "        - Milestones and checkpoints\n",
    "        - Code examples and implementation guidance when relevant\n",
    "\n",
    "        You have access to tools for time management, plan creation, web search for documentation, and file system navigation. Use them appropriately.\n",
    "\n",
    "        Consider previous planning and programming requests to build on existing plans.\n",
    "\n",
    "        {format_instructions}\n",
    "        /no_think\n",
    "        \"\"\".strip(),\n",
    "        ),\n",
    "        (\"human\", \"Previous context: {context}\\n\\nRequest: {query}\"),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "Hstk",
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_parser = PydanticOutputParser(pydantic_object=MemoryUpdate)\n",
    "\n",
    "MEMORY_PROMPT = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"\"\"\n",
    "        You are a memory manager for the multi-agent system.\n",
    "\n",
    "        Analyze the session and create:\n",
    "        - Concise session summary capturing key points\n",
    "        - Updated user preferences based on interaction patterns\n",
    "        - Action items for follow-up or future reference\n",
    "\n",
    "        Extract patterns like:\n",
    "        - Topics of interest\n",
    "        - Preferred response style (detailed/concise)\n",
    "        - Learning goals\n",
    "        - Technical skill level\n",
    "\n",
    "        {format_instructions}\n",
    "        /no_think\n",
    "        \"\"\".strip(),\n",
    "        ),\n",
    "        (\n",
    "            \"human\",\n",
    "            \"Session context: {context}\\n\\nPrevious memory: {previous_memory}\",\n",
    "        ),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "nWHF",
   "metadata": {},
   "outputs": [],
   "source": [
    "theory_agent = create_agent(\n",
    "    llm,\n",
    "    [search_wikipedia, get_wikipedia_article],\n",
    "    system_prompt=\"You are a theory expert. Use Wikipedia search tools to find and retrieve theoretical concepts, definitions, and explanations.\",\n",
    ")\n",
    "\n",
    "planning_agent = create_agent(\n",
    "    llm,\n",
    "    [\n",
    "        get_current_time,\n",
    "        create_study_plan,\n",
    "        list_study_materials,\n",
    "        read_study_material,\n",
    "        web_search,\n",
    "        list_files,\n",
    "        read_code_file,\n",
    "    ],\n",
    "    system_prompt=\"You are a planning and programming expert. Use tools for time management, plan creation, study materials tracking, web search for documentation, file navigation, and code reading.\",\n",
    ")\n",
    "\n",
    "memory_agent = create_agent(\n",
    "    llm,\n",
    "    [save_memory, load_memory],\n",
    "    system_prompt=\"You are a memory manager. Use save_memory and load_memory tools to manage session data.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "iLit",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def router_node(state):\n",
    "    logger.debug(f\"Router: Processing query: {state.query[:60]}...\")\n",
    "\n",
    "    context = \"\"\n",
    "    if state.session_history:\n",
    "        recent = state.session_history[-3:]\n",
    "        context = \"\\n\".join(\n",
    "            [\n",
    "                f\"- {h.get('classification', 'unknown')}: {h.get('query', '')[:50]}...\"\n",
    "                for h in recent\n",
    "            ]\n",
    "        )\n",
    "\n",
    "    messages = ROUTER_PROMPT.format_messages(\n",
    "        format_instructions=router_parser.get_format_instructions(),\n",
    "        context=context or \"No previous context\",\n",
    "        query=state.query,\n",
    "    )\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    classification = router_parser.parse(response.content)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Router: Classified as '{classification.query_type}' (confidence: {classification.confidence:.2f})\"\n",
    "    )\n",
    "    logger.debug(f\"Router: Reasoning: {classification.reasoning}\")\n",
    "\n",
    "    return {\n",
    "        \"classification\": classification,\n",
    "        \"session_history\": state.session_history\n",
    "        + [\n",
    "            {\n",
    "                \"query\": state.query,\n",
    "                \"classification\": classification.query_type,\n",
    "                \"confidence\": classification.confidence,\n",
    "                \"timestamp\": datetime.now().isoformat(),\n",
    "            }\n",
    "        ],\n",
    "        \"active_agent\": \"router\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ZHCJ",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def theory_node(state):\n",
    "    logger.debug(f\"Theory Agent: ACTIVATED for query: {state.query[:60]}...\")\n",
    "\n",
    "    context = \"\"\n",
    "    if state.session_history:\n",
    "        theory_history = [\n",
    "            h for h in state.session_history if h.get(\"classification\") == \"theory\"\n",
    "        ]\n",
    "        if theory_history:\n",
    "            context = \"Previous theory topics: \" + \", \".join(\n",
    "                [h.get(\"query\", \"\")[:30] + \"...\" for h in theory_history[-2:]]\n",
    "            )\n",
    "\n",
    "    logger.debug(\n",
    "        \"Theory Agent: Using Wikipedia search tools for theoretical content\"\n",
    "    )\n",
    "    tool_result = await theory_agent.ainvoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f\"Help answer this theoretical question: {state.query}. Use search_wikipedia to find relevant concepts and get_wikipedia_article for detailed information.\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    logger.debug(\n",
    "        f\"Theory Agent: Tool execution result: {str(tool_result.get('messages', []))[:150]}\"\n",
    "    )\n",
    "\n",
    "    messages = THEORY_PROMPT.format_messages(\n",
    "        format_instructions=theory_parser.get_format_instructions(),\n",
    "        context=context or \"No previous theory context\",\n",
    "        query=state.query\n",
    "        + f\"\\n\\nWikipedia search results: {str(tool_result.get('messages', []))}\",\n",
    "    )\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    theory_response = theory_parser.parse(response.content)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Theory Agent: Generated response with {len(theory_response.key_concepts)} key concepts\"\n",
    "    )\n",
    "    logger.debug(\n",
    "        f\"Theory Agent: Key concepts: {', '.join(theory_response.key_concepts[:3])}\"\n",
    "    )\n",
    "\n",
    "    return {\"theory_response\": theory_response, \"active_agent\": \"theory\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ROlb",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def planning_node(state):\n",
    "    logger.debug(f\"Planning Agent: ACTIVATED for query: {state.query[:60]}...\")\n",
    "\n",
    "    context = \"\"\n",
    "    if state.session_history:\n",
    "        planning_history = [\n",
    "            h\n",
    "            for h in state.session_history\n",
    "            if h.get(\"classification\") == \"planning\"\n",
    "        ]\n",
    "        if planning_history:\n",
    "            context = \"Previous plans: \" + \", \".join(\n",
    "                [h.get(\"query\", \"\")[:30] + \"...\" for h in planning_history[-2:]]\n",
    "            )\n",
    "\n",
    "    logger.debug(\"Planning Agent: Using time, planning, and study materials tools\")\n",
    "    tool_result = await planning_agent.ainvoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f\"Help with this planning request: {state.query}. Use get_current_time, create_study_plan, list_study_materials, and read_study_material tools as needed.\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    logger.debug(\n",
    "        f\"Planning Agent: Tool execution result: {str(tool_result.get('messages', []))[:100]}\"\n",
    "    )\n",
    "\n",
    "    messages = PLANNING_PROMPT.format_messages(\n",
    "        format_instructions=planning_parser.get_format_instructions(),\n",
    "        context=context or \"No previous planning context\",\n",
    "        query=state.query\n",
    "        + f\"\\n\\nTool output: {str(tool_result.get('messages', []))}\",\n",
    "    )\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    planning_response = planning_parser.parse(response.content)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Planning Agent: Created plan with duration: {planning_response.estimated_duration}\"\n",
    "    )\n",
    "    logger.debug(\n",
    "        f\"Planning Agent: {len(planning_response.recommendations)} recommendations\"\n",
    "    )\n",
    "\n",
    "    return {\"planning_response\": planning_response, \"active_agent\": \"planning\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "qnkX",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def memory_node(state):\n",
    "    logger.debug(\n",
    "        \"Memory Agent: ACTIVATED - Processing session and generating final response\"\n",
    "    )\n",
    "\n",
    "    logger.debug(\"Memory Agent: Loading existing memory via tool\")\n",
    "    memory_load_result = await memory_agent.ainvoke(\n",
    "        {\"messages\": [HumanMessage(content=\"Load current memory\")]}\n",
    "    )\n",
    "    previous_memory = str(memory_load_result.get(\"messages\", [{}]))\n",
    "    logger.debug(f\"Memory Agent: Loaded memory: {previous_memory[:100]}\")\n",
    "\n",
    "    context_parts = [f\"User query: {state.query}\"]\n",
    "\n",
    "    if state.classification:\n",
    "        context_parts.append(\n",
    "            f\"Classification: {state.classification.query_type} (confidence: {state.classification.confidence})\"\n",
    "        )\n",
    "        context_parts.append(f\"Reasoning: {state.classification.reasoning}\")\n",
    "\n",
    "    if state.theory_response:\n",
    "        context_parts.append(\n",
    "            f\"Theory response: {state.theory_response.answer[:150]}...\"\n",
    "        )\n",
    "        context_parts.append(\n",
    "            f\"Key concepts: {', '.join(state.theory_response.key_concepts[:3])}\"\n",
    "        )\n",
    "\n",
    "    if state.planning_response:\n",
    "        context_parts.append(\n",
    "            f\"Planning response: {json.dumps(state.planning_response.plan)[:150]}...\"\n",
    "        )\n",
    "        context_parts.append(\n",
    "            f\"Duration: {state.planning_response.estimated_duration}\"\n",
    "        )\n",
    "\n",
    "    context = \"\\n\".join(context_parts)\n",
    "\n",
    "    messages = MEMORY_PROMPT.format_messages(\n",
    "        format_instructions=memory_parser.get_format_instructions(),\n",
    "        context=context,\n",
    "        previous_memory=previous_memory,\n",
    "    )\n",
    "\n",
    "    response = await llm.ainvoke(messages)\n",
    "    memory_update = memory_parser.parse(response.content)\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Memory Agent: Session summary: {memory_update.session_summary[:100]}\"\n",
    "    )\n",
    "    logger.debug(f\"Memory Agent: {len(memory_update.action_items)} action items\")\n",
    "\n",
    "    updated_history = state.session_history + [\n",
    "        {\"summary\": memory_update.session_summary}\n",
    "    ]\n",
    "    updated_prefs = {\n",
    "        **state.user_preferences,\n",
    "        **memory_update.user_preferences_updated,\n",
    "    }\n",
    "\n",
    "    logger.debug(\"Memory Agent: Saving updated memory via tool\")\n",
    "    save_result = await memory_agent.ainvoke(\n",
    "        {\n",
    "            \"messages\": [\n",
    "                HumanMessage(\n",
    "                    content=f\"Save this memory - history: {json.dumps(updated_history)}, preferences: {json.dumps(updated_prefs)}\"\n",
    "                )\n",
    "            ]\n",
    "        }\n",
    "    )\n",
    "    logger.debug(\n",
    "        f\"Memory Agent: Save result: {str(save_result.get('messages', []))[:50]}\"\n",
    "    )\n",
    "\n",
    "    final_response = \"# Multi-Agent Assistant Response\\n\\n\"\n",
    "\n",
    "    if state.theory_response:\n",
    "        final_response += (\n",
    "            f\"## Theoretical Analysis\\n\\n{state.theory_response.answer}\\n\\n\"\n",
    "        )\n",
    "        if state.theory_response.key_concepts:\n",
    "            final_response += f\"**Key Concepts:** {', '.join(state.theory_response.key_concepts)}\\n\\n\"\n",
    "        if state.theory_response.references:\n",
    "            final_response += (\n",
    "                \"**References:**\\n\"\n",
    "                + \"\\n\".join(\n",
    "                    [f\"- {ref}\" for ref in state.theory_response.references]\n",
    "                )\n",
    "                + \"\\n\\n\"\n",
    "            )\n",
    "\n",
    "    elif state.planning_response:\n",
    "        final_response += f\"## Study Plan\\n\\n```json\\n{json.dumps(state.planning_response.plan, indent=2)}\\n```\\n\\n\"\n",
    "        final_response += f\"**Estimated Duration:** {state.planning_response.estimated_duration}\\n\\n\"\n",
    "        if state.planning_response.recommendations:\n",
    "            final_response += (\n",
    "                \"**Recommendations:**\\n\"\n",
    "                + \"\\n\".join(\n",
    "                    [f\"- {rec}\" for rec in state.planning_response.recommendations]\n",
    "                )\n",
    "                + \"\\n\\n\"\n",
    "            )\n",
    "\n",
    "    else:\n",
    "        final_response += (\n",
    "            \"I've analyzed your query. Please rephrase for better routing.\\n\\n\"\n",
    "        )\n",
    "\n",
    "    final_response += (\n",
    "        f\"---\\n\\n**Session Summary:** {memory_update.session_summary}\\n\\n\"\n",
    "    )\n",
    "    if memory_update.action_items:\n",
    "        final_response += \"**Action Items:**\\n\" + \"\\n\".join(\n",
    "            [f\"- {item}\" for item in memory_update.action_items]\n",
    "        )\n",
    "\n",
    "    logger.debug(\n",
    "        f\"Memory Agent: Final response length: {len(final_response)} chars\"\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"memory_update\": memory_update,\n",
    "        \"final_response\": final_response,\n",
    "        \"user_preferences\": updated_prefs,\n",
    "        \"active_agent\": \"memory\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "TqIu",
   "metadata": {},
   "outputs": [],
   "source": [
    "def route_query(state) -> str:\n",
    "    if not state.classification:\n",
    "        logger.warning(\"Router: No classification found, routing to memory\")\n",
    "        return \"memory\"\n",
    "\n",
    "    route = state.classification.query_type\n",
    "\n",
    "    if route == \"theory\":\n",
    "        logger.debug(\"Router: Routing to THEORY agent\")\n",
    "        return \"theory\"\n",
    "    elif route == \"planning\":\n",
    "        logger.debug(\"Router: Routing to PLANNING agent\")\n",
    "        return \"planning\"\n",
    "    else:\n",
    "        logger.debug(\"Router: Routing to MEMORY agent (general query)\")\n",
    "        return \"memory\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "Vxnm",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow = StateGraph(MultiAgentState)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "DnEU",
   "metadata": {},
   "outputs": [],
   "source": [
    "workflow.add_node(\"router\", router_node)\n",
    "workflow.add_node(\"theory\", theory_node)\n",
    "workflow.add_node(\"planning\", planning_node)\n",
    "workflow.add_node(\"memory\", memory_node)\n",
    "\n",
    "workflow.set_entry_point(\"router\")\n",
    "\n",
    "workflow.add_conditional_edges(\n",
    "    \"router\",\n",
    "    route_query,\n",
    "    {\n",
    "        \"theory\": \"theory\",\n",
    "        \"planning\": \"planning\",\n",
    "        \"memory\": \"memory\",\n",
    "    },\n",
    ")\n",
    "\n",
    "workflow.add_edge(\"theory\", \"memory\")\n",
    "workflow.add_edge(\"planning\", \"memory\")\n",
    "\n",
    "workflow.add_edge(\"memory\", END)\n",
    "\n",
    "app = workflow.compile()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ulZA",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Визуализация графа"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ecfG",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<marimo-mermaid data-diagram='&quot;---&#92;nconfig:&#92;n  flowchart:&#92;n    curve: linear&#92;n---&#92;ngraph TD;&#92;n&#92;t__start__([&lt;p&gt;__start__&lt;/p&gt;]):::first&#92;n&#92;trouter(router)&#92;n&#92;ttheory(theory)&#92;n&#92;tplanning(planning)&#92;n&#92;tmemory(memory)&#92;n&#92;t__end__([&lt;p&gt;__end__&lt;/p&gt;]):::last&#92;n&#92;t__start__ --&gt; router;&#92;n&#92;tplanning --&gt; memory;&#92;n&#92;trouter -.-&gt; memory;&#92;n&#92;trouter -.-&gt; planning;&#92;n&#92;trouter -.-&gt; theory;&#92;n&#92;ttheory --&gt; memory;&#92;n&#92;tmemory --&gt; __end__;&#92;n&#92;tclassDef default fill:#f2f0ff,line-height:1.2&#92;n&#92;tclassDef first fill-opacity:0&#92;n&#92;tclassDef last fill:#bfb6fc&#92;n&quot;'></marimo-mermaid>"
      ],
      "text/plain": [
       "Html()"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "b = app.get_graph().draw_mermaid_png()\n",
    "Image(data=b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Pvdt",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "## Оценка системы - Запуск реальных экспериментов\n",
    "\n",
    "### Тестовые запросы\n",
    "Тестируем систему на 5 различных запросах, охватывающих все типы агентов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ZBYS",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_queries = [\n",
    "    {\n",
    "        \"id\": 1,\n",
    "        \"query\": \"Каковы ключевые вызовы при реализации мультиагентных систем с использованием LLM?\",\n",
    "        \"expected_agent\": \"theory\",\n",
    "        \"description\": \"Концептуальный вопрос о МАС и LLM\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 2,\n",
    "        \"query\": \"Создай 10-часовой план изучения мультиагентных систем\",\n",
    "        \"expected_agent\": \"planning\",\n",
    "        \"description\": \"Запрос на планирование учебного расписания\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 3,\n",
    "        \"query\": \"В чём различия между паттернами supervisor и sequential workflow в МАС?\",\n",
    "        \"expected_agent\": \"theory\",\n",
    "        \"description\": \"Теоретический вопрос сравнения\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 4,\n",
    "        \"query\": \"Помоги организовать 5-дневное расписание для изучения основ LangGraph\",\n",
    "        \"expected_agent\": \"planning\",\n",
    "        \"description\": \"Запрос на планирование с конкретной длительностью\",\n",
    "    },\n",
    "    {\n",
    "        \"id\": 5,\n",
    "        \"query\": \"Объясни концепцию координации и коммуникации агентов в мультиагентных системах\",\n",
    "        \"expected_agent\": \"theory\",\n",
    "        \"description\": \"Теоретический вопрос о координации агентов\",\n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aLJB",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def run_test_query(query_text: str):\n",
    "    logger.debug(f\"Starting test query: {query_text[:60]}...\")\n",
    "    state = MultiAgentState(query=query_text)\n",
    "    result = await app.ainvoke(state)\n",
    "    logger.debug(f\"Test completed. Active agent: {result.get('active_agent')}\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nHfw",
   "metadata": {
    "marimo": {
     "config": {
      "hide_code": true
     }
    }
   },
   "source": [
    "### Запуск экспериментов\n",
    "\n",
    "Выполните ячейку ниже для запуска всех 5 тестовых запросов и сбора результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "xXTn",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m[DEBUG] Starting experiment batch | module=__main__ | function=<module>\u001b[0m\n",
      "\u001b[34m[DEBUG] Test #1: Концептуальный вопрос о МАС и LLM | module=__main__ | function=<module>\u001b[0m\n",
      "\u001b[34m[DEBUG] Starting test query: Каковы ключевые вызовы при реализации мультиагентных систем ... | module=__main__ | function=run_test_query\u001b[0m\n",
      "\u001b[34m[DEBUG] Router: Processing query: Каковы ключевые вызовы при реализации мультиагентных систем ... | module=__main__ | function=router_node\u001b[0m\n",
      "\u001b[34m[DEBUG] Router: Classified as 'theory' (confidence: 0.95) | module=__main__ | function=router_node\u001b[0m\n",
      "\u001b[34m[DEBUG] Router: Reasoning: The query is asking about the key challenges in implementing multi-agent systems using Large Language Models (LLMs). This falls under theoretical and conceptual questions related to multi-agent systems and LLMs, which aligns with the 'theory' category. | module=__main__ | function=router_node\u001b[0m\n",
      "\u001b[34m[DEBUG] Router: Routing to THEORY agent | module=__main__ | function=route_query\u001b[0m\n",
      "\u001b[34m[DEBUG] Theory Agent: ACTIVATED for query: Каковы ключевые вызовы при реализации мультиагентных систем ... | module=__main__ | function=theory_node\u001b[0m\n",
      "\u001b[34m[DEBUG] Theory Agent: Using Wikipedia search tools for theoretical content | module=__main__ | function=theory_node\u001b[0m\n",
      "\u001b[34m[DEBUG] Searching Wikipedia for: multi-agent systems with Large Language Models challenges | module=__main__ | function=search_wikipedia\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "logger.debug(\"Starting experiment batch\")\n",
    "\n",
    "experiment_results = []\n",
    "\n",
    "for test in test_queries:\n",
    "    logger.debug(f\"Test #{test['id']}: {test['description']}\")\n",
    "    result = await run_test_query(test[\"query\"])\n",
    "\n",
    "    experiment_results.append(\n",
    "        {\n",
    "            \"test_id\": test[\"id\"],\n",
    "            \"query\": test[\"query\"],\n",
    "            \"description\": test[\"description\"],\n",
    "            \"expected_agent\": test[\"expected_agent\"],\n",
    "            \"actual_agent\": result.get(\"classification\").query_type\n",
    "            if result.get(\"classification\")\n",
    "            else \"unknown\",\n",
    "            \"confidence\": result.get(\"classification\").confidence\n",
    "            if result.get(\"classification\")\n",
    "            else 0.0,\n",
    "            \"reasoning\": result.get(\"classification\").reasoning\n",
    "            if result.get(\"classification\")\n",
    "            else \"\",\n",
    "            \"response\": result.get(\"final_response\")\n",
    "            if result.get(\"final_response\")\n",
    "            else \"\",\n",
    "            \"memory_summary\": result.get(\"memory_update\").session_summary\n",
    "            if result.get(\"memory_update\")\n",
    "            else \"\",\n",
    "            \"tools_used\": result.get(\"active_agent\"),\n",
    "        }\n",
    "    )\n",
    "\n",
    "logger.debug(\"Experiment batch completed\")\n",
    "\n",
    "experiment_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "AjVT",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
